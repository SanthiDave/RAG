# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HQiRpOXiR-czblr8AR0v8nxYR_gjS3YW

# Testing the working of the endpoint & credentials using Langchain Azure OpenAI
"""

!pip install langchain-openai
import os
from langchain_openai import AzureOpenAI
from langchain_core.messages import HumanMessage
import base64
from google.colab import drive
from google.colab import userdata

# Set environment variables
os.environ["AZURE_OPENAI_API_KEY"] = userdata.get('AZURE_API_KEY')
os.environ["AZURE_OPENAI_ENDPOINT"] = userdata.get('AZURE_ENDPOINT')

# Initialize Azure OpenAI client
model = AzureChatOpenAI(
    azure_deployment="chatpluso",
    openai_api_version="2024-02-15-preview",
)

# Test message
messages = [HumanMessage(content="Hello! Can you confirm this is working?")]
response = model.invoke(messages)
print("Response:", response.content)

# Testing an image
drive.mount('/content/drive')

def encode_image_to_base64(image_path):
    with open(image_path, 'rb') as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

image_path = '/content/drive/MyDrive/Materials_Usage_Diagram.png'
base64_image = encode_image_to_base64(image_path)

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            }
        ]
    }
]

response = model.invoke(messages)
print("Vision Analysis:", response)